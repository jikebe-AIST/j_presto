#!/usr/bin/env python3

import argparse
import numpy as np
from scipy.stats import norm
from scipy.optimize import minimize
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C

def read_score_file(score_file):
    scores = {}
    with open(score_file, 'r') as f:
        for line in f:
            line = line.strip()
            if line.startswith("#") or not line:
                continue
            parts = line.split()
            traj_id = int(parts[0])
            score = float(parts[1])
            scores[traj_id] = score
    return scores

def read_lnP_file(lnP_file):
    with open(lnP_file, 'r') as f:
        lines = f.readlines()
    
    eP_matrix = []
    for line in lines:
        if not line.strip():
            continue
        vals = []
        for val in line.strip().split():
            try:
                v = float(val)
                if np.isnan(v):  # NaN = 欠損値
                    vals.append(np.nan)
                else:
                    vals.append(v)
            except ValueError:
                vals.append(np.nan)
        eP_matrix.append(vals)

    eP_array = np.array(eP_matrix)  # shape: (n_bins, 1 + n_traj)
    lambda_vals = eP_array[:, 0]
    eP_vals = eP_array[:, 1:]
    return lambda_vals, eP_vals.T  # shape: (n_traj, n_bins)

def expected_improvement(x, model, y_max):
    x = x.reshape(1, -1)
    mu, sigma = model.predict(x, return_std=True)
    sigma = sigma.reshape(-1)
    with np.errstate(divide='warn'):
        Z = (mu - y_max) / sigma
        ei = (mu - y_max) * norm.cdf(Z) + sigma * norm.pdf(Z)
        ei[sigma == 0.0] = 0.0
    return -ei[0]  # minimize for optimizer

def optimize_lnP(X, y):
    kernel = C(1.0) * RBF()
    gpr = GaussianProcessRegressor(kernel=kernel, alpha=1e-6, normalize_y=True)
    gpr.fit(X, y)
    y_max = np.max(y)

    bounds = [(-3.0, 3.0)] * X.shape[1]
    x0 = np.random.randn(X.shape[1])
    res = minimize(expected_improvement, x0, args=(gpr, y_max), bounds=bounds, method='L-BFGS-B')
    return res.x, gpr.predict([res.x])[0]

def main():
    parser = argparse.ArgumentParser(description="B-ALSD optimizer using EI.")
    parser.add_argument('--score', required=True, help='Score file (trajectory ID and score)')
    parser.add_argument('--lnp', required=True, help='lnP(lambda) file (Fortran-style)')
    args = parser.parse_args()

    # Read input
    score_dict = read_score_file(args.score)
    lambda_vals, lnP_matrix = read_lnP_file(args.lnp)

    # Filter only available scores
    X = []
    y = []
    for i, row in enumerate(lnP_matrix):
        if i in score_dict and not np.isnan(row).any():
            X.append(row)
            y.append(score_dict[i])
    X = np.array(X)
    y = np.array(y)

    if len(X) < 2:
        print("Not enough valid data points for optimization.")
        return

    optimal_lnP, predicted_score = optimize_lnP(X, y)
    normalized_lnP = optimal_lnP - np.max(optimal_lnP)

    print("----- Optimal lnP(λ) Proposal -----")
    for lmbda, val in zip(lambda_vals, normalized_lnP):
        print(f"{lmbda:.5f}  {val:.5f}")
    print(f"\nPredicted score: {predicted_score:.5f}")

if __name__ == '__main__':
    main()

